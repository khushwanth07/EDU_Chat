{"id": "batch_req_678e28513198819088a115653dd5e40a", "custom_id": "email_069.txt", "response": {"status_code": 400, "request_id": "96670a022f7753709ee3ad9203150a19", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 9015 tokens (7015 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_678e285175548190bd7f53338c550d58", "custom_id": "email_072.txt", "response": {"status_code": 400, "request_id": "64f14fa278fa56236a159bdb3fe90d23", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 8372 tokens (6372 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_678e2868d6308190a11bb0c0d674d2b2", "custom_id": "email_400.txt", "response": {"status_code": 400, "request_id": "cd28bc6e5510c45d270ece7c88f2e6c0", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 9507 tokens (7507 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_678e286945788190b9be34eda7243b69", "custom_id": "email_406.txt", "response": {"status_code": 400, "request_id": "657d5923807fd6d5b46a74a5e316481a", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 9408 tokens (7408 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_678e2869873c8190bde35397568b7545", "custom_id": "email_410.txt", "response": {"status_code": 400, "request_id": "dbdf50e51621d99f5c44de8a0ed251b1", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 8713 tokens (6713 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
{"id": "batch_req_678e286996e88190a76ddfe22871dffd", "custom_id": "email_411.txt", "response": {"status_code": 400, "request_id": "8b880df8dad2aa51071b301bf8790132", "body": {"error": {"message": "This model's maximum context length is 8192 tokens. However, you requested 9031 tokens (7031 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}}, "error": null}
